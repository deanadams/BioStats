PLS <- two.b.pls(log(gdf$Csize), gdf$coords, print.progress = FALSE)
plot(PLS)
# Group Allometries
fit <- procD.lm(coords ~ Csize * species * site, data=gdf, iter=0,
print.progress = FALSE)
# CAC (should not change from last time; model change has no effect)
plotAllometry(fit, size = gdf$Csize, logsz = TRUE, method = "CAC",
pch = 19)
# Predline
plotAllometry(fit, size = gdf$Csize, logsz = TRUE, method = "PredLine",
pch = 19, col = as.numeric(interaction(gdf$species, gdf$site)))
# RegScore
plotAllometry(fit, size = gdf$Csize, logsz = TRUE, method = "RegScore",
pch = 19, col = as.numeric(interaction(gdf$species, gdf$site)))
pc.plot <- plotAllometry(fit, size = gdf$Csize, logsz = TRUE,
method = "size.shape",
pch = 19, col = as.numeric(interaction(gdf$species, gdf$site)))
summary(pc.plot$size.shape.PCA)
fit3 <- procD.lm(coords ~ species, data = gdf, iter = 0,
print.progress = FALSE)
plotAllometry(fit3, size = gdf$Csize, logsz = TRUE, method = "RegScore",
pch = 19, col = as.numeric(gdf$species))
# Group Allometries
fit <- procD.lm(coords ~ Csize + species * site, data=gdf, iter=0,
print.progress = FALSE)
# CAC (should not change from last time; model change has no effect)
plotAllometry(fit, size = gdf$Csize, logsz = TRUE, method = "CAC",
pch = 19)
# Predline
plotAllometry(fit, size = gdf$Csize, logsz = TRUE, method = "PredLine",
pch = 19, col = as.numeric(interaction(gdf$species, gdf$site)))
# Group Allometries
fit.c <- procD.lm(coords ~ Csize + species * site, data=gdf, iter=0,
print.progress = FALSE)
# Predline
plotAllometry(fit.c, size = gdf$Csize, logsz = TRUE, method = "PredLine",
pch = 19, col = as.numeric(interaction(gdf$species, gdf$site)))
# Group Allometries
fit <- procD.lm(coords ~ Csize * species * site, data=gdf, iter=0,
print.progress = FALSE)
# Predline
plotAllometry(fit, size = gdf$Csize, logsz = TRUE, method = "PredLine",
pch = 19, col = as.numeric(interaction(gdf$species, gdf$site)))
# Simple allometry
data(plethodon)
Y.gpa <- gpagen(plethodon$land, print.progress = FALSE)    #GPA-alignment
gdf <- geomorph.data.frame(Y.gpa, site = plethodon$site,
species = plethodon$species)
# Group Allometries
fit <- procD.lm(coords ~ Csize * species * site, data=gdf, iter=0,
print.progress = FALSE)
# Predline
plotAllometry(fit, size = gdf$Csize, logsz = TRUE, method = "PredLine",
pch = 19, col = as.numeric(interaction(gdf$species, gdf$site)))
# Group Allometries
fit.c <- procD.lm(coords ~ Csize + species * site, data=gdf, iter=0,
print.progress = FALSE)
# Predline
plotAllometry(fit.c, size = gdf$Csize, logsz = TRUE, method = "PredLine",
pch = 19, col = as.numeric(interaction(gdf$species, gdf$site)))
anova(fit)
# Group Allometries
fit <- procD.lm(coords ~ Csize * species * site, data=gdf, iter=999,
print.progress = FALSE)
anova(fit)
gps <- intersect(plethodon$site, plethodon$species)
gps
gps <- interaction(plethodon$site, plethodon$species)
gps
gdf <- geomorph.data.frame(Y.gpa, gps  = gps)
# Group Allometries
fit <- procD.lm(coords ~ Csize * gps, data=gdf, iter=999,
print.progress = FALSE)
anova(fit)
# Predline
plotAllometry(fit, size = gdf$Csize, logsz = TRUE, method = "PredLine",
pch = 19, col = as.numeric(interaction(gdf$species, gdf$site)))
# Predline
plotAllometry(fit, size = gdf$Csize, logsz = TRUE, method = "PredLine",
pch = 19, col = gps)
# Group Allometries
fit.c <- procD.lm(coords ~ Csize + gps, data=gdf, iter=999,
print.progress = FALSE)
anova(fit.c)
# Predline
plotAllometry(fit.c, size = gdf$Csize, logsz = TRUE, method = "PredLine",
pch = 19, col = gps)
devtools::install_github('geomorphR/geomorph', ref="Develop", build_vignettes = TRUE)
install.packages("rgl")
devtools::install_github('geomorphR/geomorph', ref="Develop", build_vignettes = TRUE)
setwd("C:/DeanData/Teaching/EEOB590_AdvBiostat/BioStats/LabData")
bumpus<-read.csv("Data/bumpus.csv",header=T)
bumpus.data<-log(as.matrix(bumpus[,(5:13)])) # matrix of log-linear measurements
sex<-as.factor(bumpus[,2])
surv<-as.factor(bumpus[,4])
SexBySurv<-as.factor(paste(sex,surv))
Y<-as.matrix(bumpus.data[,1])
X1<-bumpus.data[,2]
X2<-bumpus.data[,3]
library(RRPP)
mydat <- rrpp.data.frame(Y = Y, X1 = X1, X2 = X2, sex = sex, surv = surv, SexBySurv = SexBySurv)
#__________________________________________________________________________#
#simple linear regression  (Model I Regression)
lm(Y~X1)
#more information
model1<-lm(Y~X1)
summary(model1)	#provides regression coefficients
anova(model1)	#provides model term tests
plot(X1,Y,pch=21, bg="black", cex=2)
abline(model1,lwd=2,col="red")
#Lots of components in model, such as:
model1$fitted.values
model1$residuals
#Regression evaluated via residual randomization (RRPP)
model2 <- lm.rrpp(Y~X1, print.progress = FALSE, data = mydat)
anova(model2)
anova(model1)	#Identical to parametric results
coef(model2)
coef(model1)
#__________________________________________________________________________#
#### Model II Regression
library(lmodel2)
lmodel2(Y~X1,nperm=999)
RMA<-lmodel2(Y~X1)
plot(RMA, pch=21,cex=2, bg="black")
abline(model1,lwd=2,col="blue")
#__________________________________________________________________________#
#multiple regression
summary(lm(Y~X1+X2))
anova(lm(Y~X1+X2))
#via RRPP
anova(lm.rrpp(Y~X1+X2,print.progress = FALSE, data=mydat))
cor(X1,X2)  #hmm, there is multicollinearity in the X-variables. Perhaps use type II SS.
anova(lm.rrpp(Y~X1+X2,print.progress = FALSE, data=mydat,SS.type = "II"))
# Plot for multiple regression
#install.packages("scatterplot3d")
library(scatterplot3d)
plot<-scatterplot3d(X1,X2,Y)
plot$plane3d(lm(Y~X1+X2))
#__________________________________________________________________________#
#polynomial regression
fit  <- lm(Y~X1) #first degree
fit2 <- lm(Y~poly(X1,2,raw=TRUE))#second degree
fit3 <- lm(Y~poly(X1,3,raw=TRUE))#third degree
fit4 <- lm(Y~poly(X1,4,raw=TRUE))#fourth degree
#evaluate models
anova(fit)
anova(fit,fit2)  #In this case, adding polynomial terms NOT an improvement
anova(fit2,fit3)
anova(fit3,fit4)
plot(X1,Y)
abline(model1,col="red")
xx <-seq(min(X1),max(X1),length=100)
lines(xx, predict(fit2, data.frame(X1=xx)), col="blue")
lines(xx, predict(fit3, data.frame(X1=xx)), col="green")
lines(xx, predict(fit4, data.frame(X1=xx)), col="purple")
#__________________________________________________________________________#
###ANCOVA
anova(lm(Y~X2*SexBySurv))
#Implies slopes for M and F statistically equivalent, so drop and re-run
anova(lm(Y~X2+SexBySurv))
model.ancova<-lm(Y~X2+SexBySurv)
56/2000
############ let us begin with a comparison of implementations
mymean<-function(x){
n<-length(x)
tmp<-0
for (i in 1:n){
tmp<-tmp+x[i]
}
mn<-tmp/n
return(mn)
}
x<-matrix(rnorm(1000))
n<-length(x)
library(microbenchmark)
library(ggplot2)
microbenchmark(mean(x),apply(x,2,mean), sum(x)/length(x),mymean(x),colSums(x)/length(x))
############ Evaluating choke-points in code
#Example
library(aprof)
source("07-pls.slow.r")
tmp<-tempfile() #create tmp file for saving profiler output
Rprof(tmp,line.profiling=TRUE)  #profile the function
x<-matrix(rnorm(1000),ncol=10)
y<-matrix(rnorm(1000),ncol=10)
pls.slow(x,y)
Rprof(append=FALSE)
fooaprof<-aprof("07-pls.slow.r",tmp) #Create aprof object
plot(fooaprof)
iter<-99
SS<-array(NA,iter) #pre-allocate
newSS<-function(iter){ #'on the fly'
SS<-NULL
for (i in 1:iter){SS<-rbind(SS,NA)}
return(SS)
}
microbenchmark(SS<-array(NA,99), x<-newSS(99))
microbenchmark(SS<-array(NA,9999), x<-newSS(9999),times=10)
x<-cbind(1,matrix(rnorm(1000),ncol=10))
y<-matrix(rnorm(100))
all.calc<-function(x,y){
coef.r<-array(NA,dim=c(999,ncol(x)))
for (i in 1:999){
y.r<-y[sample(nrow(y)),]
coef.r[i,]<-solve(t(x)%*%x)%*%t(x)%*%y.r
}
}
hat.calc<-function(x,y){
hat<-solve(t(x)%*%x)%*%t(x)
coef.r<-array(NA,dim=c(999,ncol(x)))
for (i in 1:999){
y.r<-y[sample(nrow(y)),]
coef.r[i,]<-hat%*%y.r
}
}
microbenchmark(all.calc(x,y),hat.calc(x,y),times=10)
#3:  Use lower-level functions
x<-matrix(rnorm(10000),ncol=2)
xf<-cbind(1,x)
y<-matrix(rnorm(nrow(x)))
lm(y~x)  #Common method
solve(t(xf)%*%xf)%*%t(xf)%*%y
crossprod(solve(crossprod(xf)),crossprod(xf,y))
lm.fit(xf,y)$coefficients
.lm.fit(xf,y)$coefficients  ### NOTE: a very low-level function (cannot use in packages submitted to CRAN)
qr.coef(qr(xf),y)
microbenchmark(
lm(y~x),
solve(t(xf)%*%xf)%*%t(xf)%*%y,
crossprod(solve(crossprod(xf)),crossprod(xf,y)),
lm.fit(xf,y),.lm.fit(xf,y),
qr.coef(qr(xf),y)
)
###NOTE that the best implementation can change with the size of the data matrix
#Large X univ. Y
x<-matrix(rnorm(10000),ncol=50)
xf<-cbind(1,x)
y<-matrix(rnorm(nrow(x)))
microbenchmark(
lm(y~x),
solve(t(xf)%*%xf)%*%t(xf)%*%y,
crossprod(solve(crossprod(xf)),crossprod(xf,y)),
lm.fit(xf,y),.lm.fit(xf,y),
qr.coef(qr(xf),y)
)
x<-matrix(rnorm(nrow(y)))
xf<-cbind(1,x)
##Large Y univ. X
y<-matrix(rnorm(10000),ncol=100)
microbenchmark(
lm(y~x),
solve(t(xf)%*%xf)%*%t(xf)%*%y,
crossprod(solve(crossprod(xf)),crossprod(xf,y)),
lm.fit(xf,y),.lm.fit(xf,y),
qr.coef(qr(xf),y)
)
#large Y and X
y<-matrix(rnorm(20000),ncol=100)
x<-matrix(rnorm(10000),ncol=50)
xf<-cbind(1,x)
microbenchmark(
lm(y~x),
solve(t(xf)%*%xf)%*%t(xf)%*%y,
crossprod(solve(crossprod(xf)),crossprod(xf,y)),
lm.fit(xf,y),.lm.fit(xf,y),
qr.coef(qr(xf),y)
)
##Large Y univ. X
y<-matrix(rnorm(10000),ncol=100)
x<-matrix(rnorm(nrow(y)))
xf<-cbind(1,x)
microbenchmark(
lm(y~x),
solve(t(xf)%*%xf)%*%t(xf)%*%y,
crossprod(solve(crossprod(xf)),crossprod(xf,y)),
lm.fit(xf,y),.lm.fit(xf,y),
qr.coef(qr(xf),y)
)
#large Y and X
y<-matrix(rnorm(20000),ncol=100)
x<-matrix(rnorm(10000),ncol=50)
xf<-cbind(1,x)
microbenchmark(
lm(y~x),
solve(t(xf)%*%xf)%*%t(xf)%*%y,
crossprod(solve(crossprod(xf)),crossprod(xf,y)),
lm.fit(xf,y),.lm.fit(xf,y),
qr.coef(qr(xf),y)
)
#4: Vectorize when possible. Don't speak R with a 'C accent'
fn1<-function(x){
means<-array(0,ncol(x))
for(i in 1:ncol(x)){
for(j in 1:nrow(x)){
means[i]<-means[i]+x[j,i]
}
}
means<-means/nrow(x)
return(means)
}
x<-matrix(rnorm(1000*1000),ncol=1000)
microbenchmark(fn1(x),colMeans(x),apply(x,2,mean),times=10)
###
x <- matrix(rnorm(1000*10000), ncol=1000)
fn1<-function(x){
mx <- rep(NA, nrow(x))
for(i in 1:nrow(x)){ mx[i] <- max(x[i,])  }
return(mx)
}
microbenchmark(fn1(x),apply(x,1,max),times=10)  #loop is faster here
source('07-pls.slow.r')
x<-matrix(rnorm(10000),ncol=10)
y<-matrix(rnorm(20000),ncol=20)
microbenchmark(pls.slow(x,y),pls.fast(x,y),times=5)
#####PLS: compare new and old versions
source('07-pls.fast.r')
setwd("C:/DeanData/Teaching/EEOB590_AdvBiostat/BioStats/LabData")
#####PLS: compare new and old versions
source('07-pls.fast.r')
source('07-pls.slow.r')
x<-matrix(rnorm(10000),ncol=10)
y<-matrix(rnorm(20000),ncol=20)
microbenchmark(pls.slow(x,y),pls.fast(x,y),times=5)
View(pls.fast)
View(pls.slow)
########################
#	PCA: Principal Components Analysis
library(RRPP)
library(vegan)
bumpus<-read.csv("data/bumpus.csv",header=T)
Y<-bumpus[,5:12]
Y <- scale(Y, scale = FALSE) #center data
gp.bumpus <- bumpus$sex
pca.bumpus<-prcomp(Y)
summary(pca.bumpus)
PC.scores<-pca.bumpus$x
pca.bumpus$rotation[,1]  #1st PC axis only
plot(PC.scores,xlab="PC I", ylab="PC II",asp=1,pch=21,bg=gp.bumpus,cex = 1.5)
plot(PC.scores,xlab="PC I", ylab="PC II",asp=1,pch=21,bg=as.factor(gp.bumpus),cex = 1.5)
legend("topright", levels(gp.bumpus), pch = 21)
Y <- scale(Y, scale = FALSE) #center data
gp.bumpus <- as.factor(bumpus$sex)
pca.bumpus<-prcomp(Y)
summary(pca.bumpus)
PC.scores<-pca.bumpus$x
pca.bumpus$rotation[,1]  #1st PC axis only
plot(PC.scores,xlab="PC I", ylab="PC II",asp=1,pch=21,bg=gp.bumpus,cex = 1.5)
legend("topright", levels(gp.bumpus), pch = 21)
legend("topright", levels(gp.bumpus), pch = 21, col=levels(gp.bumpus))
legend("topright", levels(gp.bumpus), pch = 21,bg=gp.bumpus)
legend("topright", levels(gp.bumpus), pch = 21,col=gp.bumpus)
legend("topright", levels(gp.bumpus), pch = 21,col=levels(gp.bumpus))
gp.bumpus
legend("topright", levels(gp.bumpus), pch = 21,pt.bg=levels(gp.bumpus))
?legend
legend("topright", levels(gp.bumpus), pch = 21,pt.bg=1:2)
########################
#	PCA: Principal Components Analysis
library(RRPP)
library(vegan)
bumpus<-read.csv("data/bumpus.csv",header=T)
Y<-bumpus[,5:12]
Y <- scale(Y, scale = FALSE) #center data
gp.bumpus <- as.factor(bumpus$sex)
pca.bumpus<-prcomp(Y)
summary(pca.bumpus)
PC.scores<-pca.bumpus$x
pca.bumpus$rotation[,1]  #1st PC axis only
plot(PC.scores,xlab="PC I", ylab="PC II",asp=1,pch=21,bg=gp.bumpus,cex = 1.5)
legend("topright", levels(gp.bumpus), pch = 21,pt.bg=1:2)
#Eigenvalue analysis via broken stick model
screeplot(pca.bumpus,bstick = TRUE)  #implies 2 PCAs sufficient graphical representation
##Plot of actual vs. PC1-2 distances
plot(dist(Y),dist(PC.scores[,1:2]))
cor(dist(Y),dist(PC.scores[,1:2]))
### PCA via svd
svd.res<-svd(Y)
svd.res$d^2/sum(svd.res$d^2)   #same % variation per PC axis
pc.scores.svd<-svd.res$u%*%diag(svd.res$d)  #PCA scores
plot(pc.scores.svd,asp=1)
plot(pc.scores.svd,asp=1, pch=21,bg=gp.bumpus,cex = 1.5)
legend("topright", levels(gp.bumpus), pch = 21,pt.bg=1:2)
#### PCA "by hand" via eigen-analysis
vcv.bumpus<-var(Y)	#Calculate PC axes
pc.bumpus<-eigen(vcv.bumpus)
pc.bumpus$values/sum(pc.bumpus$values)   #same % variation per PC axis
pc.scores<-Y%*%pc.bumpus$vectors	#Projection
plot(pc.scores,xlab="PC I", ylab="PC II",asp=1,pch=21,bg=gp.bumpus,cex = 1.5)
legend("topright", levels(gp.bumpus), pch = 21,pt.bg=1:2)
#############Biplot with PCA
biplot(pca.bumpus)
###########################
# 	PCoA
bumpus.dist<-dist(Y)
PCoA<-cmdscale(bumpus.dist)   #from vegan
plot(PCoA,pch=21,bg=gp.bumpus,cex=1.5,asp=1)
legend("topright", levels(gp.bumpus), pch = 21,pt.bg=1:2)
#############################
#	NMDS
bumpus.nmds <- metaMDS(bumpus.dist, autotransform=FALSE, k=2)
#A nice function. Runs 20 times with different starting points; tries to avoid local optima
plot(bumpus.nmds$points, asp=1,pch=21, bg=gp.bumpus, cex=1.5,xlab="NMDS1", ylab="NMDS2")
legend("topright", levels(gp.bumpus), pch = 21,pt.bg=1:2)
#Plot of actual to plot distances (often curved)
plot(bumpus.dist, dist(scores(bumpus.nmds, display='sites'), method='eucl'), xlab='D.obs', ylab='D.plot')
data(dune)  #from vegan
dune
dune.dist<-vegdist(dune)  #default = Bray-Curtis distance
dune.nmds <- metaMDS(dune.dist, autotransform=FALSE, k=2)
#A nice function. Runs 20 times with different starting points; tries to avoid local optima
plot(dune.nmds)
plot(dune.nmds,type='t')
#Plot of actual to plot distances (often curved)
plot(dune.dist, dist(scores(dune.nmds, display='sites'), method='eucl'), xlab='D.obs', ylab='D.plot')
#################
#Correspondence Analysis
dune.cca<-cca(dune)  #from vegan
plot(dune.cca)
#Detrended Correspondence Analysis
dune.dca<-decorana(dune)
plot(dune.dca)
pca.bumpus<-prcomp(Y)
PC.scores<-pca.bumpus$x
plot(PC.scores,xlab="PC I", ylab="PC II",asp=1,pch=21,bg=gp.bumpus,cex = 1.5)
legend("topright", levels(gp.bumpus), pch = 21,pt.bg=1:2)
pc.bird<-prcomp(Y)
p.var<-pc.bird$sdev^2/sum(pc.bird$sdev^2)
p.var
pc.bird$rotation[,1]
pca.bumpus$sdev^2 / sum(pca.bumpus$sdev^2)
pca.bumpus$rotation[,1]
PCoA<-cmdscale(dist(Y))
plot(-1*PCoA[,1],PCoA[,2],pch=21,bg=gp.bumpus,cex=1.5,asp=1)
legend("topright", levels(gp.bumpus), pch = 21,pt.bg=1:2)
setwd("C:/DeanData/Teaching/EEOB590_AdvBiostat/BioStats/LabData")
rm(list=ls())
#######################
#  Some Clustering Methods
#	NOTE: phylogenetic clustering approaches found in package APE, Phangorn & others
#	  see: 'Analysis of phylogenetic and evolution in R. 2006. E. Paradis
##
#######################
rm(list=ls())
mole.data<-read.csv("Data/Lab-09.Moles.csv",header=T,row.names=1)
mole.dist<-as.dist(mole.data)
### PCoA of mole data
PCoA<-cmdscale(mole.dist)
plot(PCoA,pch=21,bg='black',cex=1.5,asp=1)
text(PCoA[,1]+1.5,PCoA[,2],row.names(mole.data))
#Some clustering methods
mole.single<-hclust(mole.dist,method="single")       #Single-link
mole.complete<-hclust(mole.dist,method="complete")   #Complete-link
mole.upgma<-hclust(mole.dist,method="average")       #UPGMA = average-link
mole.upgmc<-hclust(mole.dist,method="centroid")      #UPGMC
mole.wpgma<-hclust(mole.dist,method="mcquitty")      #WPGMA
mole.wpgmc<-hclust(mole.dist,method="median")        #WPGMC
mole.wards<-hclust(mole.dist,method="ward.D")          #Ward's
##PLOTS
plot(mole.single, hang=-1,lwd=2)
plot(as.dendrogram(mole.single),horiz=TRUE,lwd=4,xlim=c(16,-1))  #single-link
##PLOTS
plot(mole.single, hang=-1,lwd=2, main="Single Linkage")
plot(as.dendrogram(mole.single),horiz=TRUE,lwd=4,xlim=c(16,-1), main="Single Linkage")  #single-link
plot(as.dendrogram(mole.complete),horiz=TRUE,lwd=4,xlim=c(16,-1), main="Complete Linkage")  #complete-link
plot(as.dendrogram(mole.upgma),horiz=TRUE,lwd=4,xlim=c(16,-1), main="UPGMA")  #UPGMA
plot(as.dendrogram(mole.wpgma),horiz=TRUE,lwd=4,xlim=c(16,-1), main="WPGMA")  #WPGMA
plot(as.dendrogram(mole.upgmc),horiz=TRUE,lwd=4,xlim=c(16,-1), main="UPGMC")  #UPGMC
plot(as.dendrogram(mole.wpgmc),horiz=TRUE,lwd=4,xlim=c(16,-1), main="WPGMC")  #WPGMC
plot(as.dendrogram(mole.wards),horiz=TRUE,lwd=4,xlim=c(16,-1), main="Ward's")  #Ward's
plot(mole.dist,cophenetic(mole.upgma))  #NOTE that small distances better preserved
#some data (head shape in Plethodon salamanders)
library(geomorph)
data(plethodon)
PC.scores<-prcomp(two.d.array(gpagen(plethodon$land)$coords))$x
plot(PC.scores,pch=21,bg=as.factor(paste(plethodon$species,plethodon$site)),asp=1)
##UPGMA
pleth.dist<-dist(PC.scores)
pleth.upgma<-hclust(pleth.dist,method="average")
plot(as.dendrogram(pleth.upgma),horiz=TRUE,lwd=4, main="UPGMA")  #UPGMA
#PLOT of actual vs. UPGMA distances
plot(pleth.dist,cophenetic(pleth.upgma))
# SAME from PC
plot(pleth.dist,dist(PC.scores[,1:2]))
#K-means
kclusters4<-kmeans(PC.scores,4)
plot(PC.scores[,1:2],col=kclusters4$cluster)
points(kclusters4$centers, col = 1:4, pch = 8, cex=2)
kclusters3<-kmeans(PC.scores,3)
plot(PC.scores[,1:2],col=kclusters3$cluster)
points(kclusters3$centers, col = 1:3, pch = 8, cex=2)
#K-means
kclusters4<-kmeans(PC.scores,4)
plot(PC.scores[,1:2],col=kclusters4$cluster)
plot(PC.scores[,1:2],col=kclusters4$cluster,, main="K=4")
points(kclusters4$centers, col = 1:4, pch = 8, cex=2)
kclusters3<-kmeans(PC.scores,3)
plot(PC.scores[,1:2],col=kclusters3$cluster, main="K=3")
points(kclusters3$centers, col = 1:3, pch = 8, cex=2)
kclusters2<-kmeans(PC.scores,2)
kclusters2<-kmeans(PC.scores,2)
plot(PC.scores[,1:2],col=kclusters2$cluster, main="K=2")
points(kclusters2$centers, col = 1:2, pch = 8, cex=2)
#compare TESS
TESS<-array(NA,6)
for (i in 1:6){
TESS[i]<-kmeans(PC.scores,i)$tot.withinss
}
plot( TESS)  #seems to bottom out at 3 groups
plot( TESS)  #seems to bottom out at 3 groups
plot(PC.scores[,1:2],col=kclusters3$cluster, main="K=3")
points(kclusters3$centers, col = 1:3, pch = 8, cex=2)

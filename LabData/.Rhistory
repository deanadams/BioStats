a
### Some base functions
sum(a)
mean(a)
sum(a)/ length(a)
min(a)
max(a)
range(a)
var(a)
a^2		#square values
a^3
a^.5
sqrt(a)	#NaN for negative values
abs(a)
cor(a,b)
?cor   #call man page for information
ls()
rm(list=ls())   #remove items in memory
a
# Matrix operations
a<-matrix(c(1,0,4,2,-1,1),nrow=3)
b<-matrix(c(1,-1,2,1,1,0),nrow=2)
a
b
c<-t(a)	#matrix transpose
a
c
2*a	#scalar multiplication
b
c
b+c
b-c
a+b		##NOTE: non-conformable matrices (check rxc of your matrices!)
a
b
#elementwise multiplication (hadamard product)
c
b
c*b
a
b
# matrix multiplication
a%*%b		## %*% is symbol for matrix multiplication
b%*%a		## matrix order matters
rm(list=ls())
gl(2,10)	#Generate levels of a factor
?read.csv
## Read data
mydata<-read.csv(file="Data/Lab-01-RIntroData.csv",header=T)
View(mydata)
?cd
?swd
setwd("C:/DeanData/Teaching/EEOB590_AdvBiostat/BioStats/LabData")
?setwd
setwd("C:/DeanData/Teaching/EEOB590_AdvBiostat/BioStats/LabData")
mydata
Y<-as.matrix(mydata[,(2:3)])
Y
mydata[,4]
FactorA<-as.factor(mydata[,4])
Y
FactorA
Y
?apply
?sd
# The 'apply' functions (apply, sapply, tapply, etc.) loop over data and do things
apply(Y,2,sd)    #here, we obtain the std for each column of a matrix
apply(Y,1,sd)
apply(Y,2,sum)
apply(Y,2,mean)
FactorA
tapply(Y[,1],FactorA,mean)	#Obtain means for first column for levels of FactorA
tapply(Y[,2],FactorA,mean)	#Obtain means for first column for levels of FactorA
tapply(Y,FactorA,mean)		#Try entire matrix: doesn't work
dim(Y)
rowsum(Y, FactorA)
table(FactorA)
as.vector(table(FactorA))
rowsum(Y, FactorA)/as.vector(table(FactorA))    #This obtains means.  Could also use a loop.
mymean<-function(x){
n<-length(x)
tmp<-0
for (i in 1:n){
tmp<-tmp+x[i]
}
mn<-tmp/n
return(mn)
}
x<-rnorm(10)
mean(x)
mymean(x)  #works!
Y<-rnorm(10)
mean(Y)
mymean(Y)  #works!
mydata
#Some basic statistics
model1<-lm(mydata$y~mydata$x)  #run regression
model1
summary(model1)
anova(model1)  #generates anova table of results
#A plot with regression line
plot(mydata$x,mydata$y)
abline(coef(model1))
mydata$groups
model2<-lm(mydata$y~mydata$groups)  #run anova
summary(model2)
anova(model2)
class(mydata)
mydata$x
mydata$y
##### Attaching Data
attach(mydata)  #link data table to call columns by name
x
y
groups
anova(lm(y~groups))     #ANOVA
anova(lm(y~x))		#regression
anova(lm(y~x*groups))   #ANCOVA
rm(x)
##### Attaching Data
attach(mydata)  #link data table to call columns by name
anova(lm(y~groups))     #ANOVA
anova(lm(y~x))		#regression
anova(lm(y~x*groups))   #ANCOVA
###MULTIVARIATE
ymatrix<-cbind(y,y2)  #generate multivariate Y-matrix
ymatrix
summary(manova(lm(ymatrix~x*groups))) ####NOTE: notation differs slightly
ymatrix
rm(list=ls())
?save
?aov
?anova
?car:::Anova
#Enrollment Trends: 2000-2020
year <- seq(2000,2020)
ISU <- c(26845, 27823, 27898, 27380, 26380,
25741, 25462, 26160, 26856, 27975, 28682, 29887,
31040, 33241, 34732, 36001, 36660, 36321, 34992,33391,  31825)
UConn <- c(12819, 13588, 14213, 15260, 15709, 16006, 16036,
16459, 16691, 16970, 17450, 17170, 17684, 18016,
18451, 19030, 18930, 18830, 18585, 18658)
plot(year,ISU, pch=19, col='black', ylim = c(0,40000))
plot(year,ISU, pch=19, col='black', ylim = c(0,40000),l=T)
points(year,UConn,pck=19,col="blue")
length(UConn)
length(year)
UConn <- c(11,987,12819, 13588, 14213, 15260, 15709, 16006, 16036,
16459, 16691, 16970, 17450, 17170, 17684, 18016,
18451, 19030, 18930, 18830, 18585, 18658)
plot(year,ISU, pch=19, col='black', ylim = c(0,40000))
points(year,UConn,pck=19,col="blue")
length(year)
length(UConn)
UConn <- c(11987,12819, 13588, 14213, 15260, 15709, 16006, 16036,
16459, 16691, 16970, 17450, 17170, 17684, 18016,
18451, 19030, 18930, 18830, 18585, 18658)
points(year,UConn,pck=19,col="blue")
points(year,UConn,pch=19,col="blue")
plot(year,ISU, pch=19, col='black', ylim = c(0,40000), ylab = "Enrollment")
points(year,UConn,pch=19,col="blue")
legend("bottomright",c("ISU", "UConn"), lty = 1, lwd = 2, col = 1:2)
legend("bottomright",c("ISU", "UConn"), lty = 1, lwd = 2, col = 1:4)
legend("bottomright",c("ISU", "UConn"), lty = 1, lwd = 2, col = 1:4)
plot(year,ISU, pch=19, col='black', ylim = c(0,40000), ylab = "Enrollment")
points(year,UConn,pch=19,col="blue")
legend("bottomright",c("ISU", "UConn"), lty = 1, lwd = 2, col = 1:4)
legend("bottomright",c("ISU", "UConn"), lty = 1, lwd = 2, col = c("black","blue"))
plot(year,ISU, pch=19, col='black', ylim = c(0,40000), ylab = "Undergrad Enrollment")
points(year,UConn,pch=19,col="blue")
ISU <- c(22481, 23460, 23399, 22230, 21354, 20732, 20440, 21004,
21607, 22521, 23104, 24343, 25553, 27659, 28893, 30034,
30671, 30406, 29621, 28294, 26846)
plot(year,ISU, pch=19, col='black', ylim = c(0,40000), ylab = "Undergrad Enrollment")
points(year,UConn,pch=19,col="blue")
legend("bottomright",c("ISU", "UConn"), lty = 1, lwd = 2, col = c("black","blue"))
plot(year,ISU, pch=19, col='black', ylim = c(0,35000), ylab = "Undergrad Enrollment")
points(year,UConn,pch=19,col="blue")
legend("bottomright",c("ISU", "UConn"), lty = 1, lwd = 2, col = c("black","blue"))
plot(year,ISU, pch=19, col='black', ylim = c(0,35000), ylab = "Undergrad Enrollment")
points(year,UConn,pch=19,col="blue")
legend("bottomright",c("ISU", "UConn"), lty = 1, lwd = 2, col = c("black","blue"))
#__________________________________________________________________________#
#Generating Random Numbers
#Of paramount importance when running Monte Carlo simulations
rm(list=ls())
#normal distribution
x <- rnorm(5000)
hist(x,20,freq=T)
x2<-runif(5000)
hist(x2,20,freq=T)
z1<-rnorm(500, mean = 1, sd = 0.3)
hist(z1,20,freq=T)
z2<-rnorm(500, mean = 3, sd = 0.3)
plot(z1,z2)
z3<-runif(500, 0, 1)
z4<-runif(500, 0,1)
plot(z3,z4)
##Setting the 'seed' for random number generation
#IMPORTANT for checking simulations prior to full run
set.seed(2)  #sets the seed
rnorm(10)
set.seed(2)  #sets the seed
rnorm(10)
rnorm(10)		#note that the seed is not held indefinitely in memory)
## Simulate CORRELATED Data Using MVTNORM
##basic idea: simulate rnorm vectors, & multiply by decomposition of a covariance matrix
## covariance matrix specifies correlation structure
library(mvtnorm)
corr.val<-0.7
a <- rmvnorm(n=500,mean=c(0,0),sigma=matrix(c(1,corr.val,corr.val,1),2,2))
cor(a)
plot(a)
#__________________________________________________________________________#
###Shuffle Data: i.e. resampling without replacement
rm(list=ls())
x <- 1:10
#dim(x)<-c(10,1) #force dimensions to make column vector
x
sample(x)	# Randomize the order of locations
sample(x,replace=FALSE)	#more explicit
sample(x,(length(x)-2),replace=FALSE)	#sub-sample
#__________________________________________________________________________#
# WHEN SAMPLE CAN GET US IN TROUBLE!!!!!!
x <- 1:10
y<-cbind(x,x,x)
y
sample(y,replace=FALSE)    #We did not tell it to preserve rows!!
y[sample(nrow(y)),]   	   # ROWS Preserved (needed for resampling multivariate data)
#__________________________________________________________________________#
#Simple Randomization Test
rm(list=ls())
bumpus<-read.csv("Data/bumpus.csv",header=T)
bumpus.data<-log(bumpus[,(5:13)]) # set of log-linear measurements
sex<-as.factor(bumpus[,2])
TL<-bumpus.data$TL
#Observed data
t.test(formula=bumpus.data$TL~sex)
plot(sex,bumpus.data$TL,ylab="Total Length")
t.obs<-t.test(formula=bumpus.data$TL~sex)$statistic[[1]]  #grab t-statistic from frame
t.obs
#Randomization Test
permute<-999
P.1tailed<-P.2tailed<-1
t.rand.vec<-array(NA,(permute+1))
t.rand.vec[permute+1]<-t.obs
for(i in 1:permute){
###Shuffle Data
y.rand<-sample(bumpus.data$TL)  #NOTE: notation works ONLY for single variable
###Run analysis on random data
t.rand.vec[i]<-t.test(formula=y.rand~sex)$statistic[[1]]
}  #end permute
##Significance assessment
P.1tailed<-length(which(t.rand.vec<=t.rand.vec[permute+1])) / (permute+1)  #because observed is negative
P.2tailed<-length(which(abs(t.rand.vec)>=abs(t.rand.vec[permute+1]))) / (permute+1)
P.1tailed
P.2tailed
####Plot
hist(t.rand.vec,20,freq=T,col="gray")
segments(t.obs, 0, t.obs, 50)  ##Plot Observed value
#__________________________________________________________________________#
# Bootstrapping Data
x <- 1:10
sample(x,replace=TRUE)
#Observed mean and CI
mean.TL<-mean(TL)
mean.TL
int<-1.96*sqrt(var(TL)/length(TL))
CIlow<-mean.TL-int
CIhi<-mean.TL+int
CIlow
CIhi
#Bootstrap data
boot.mean<-numeric(1000)
for (i in 1:1000){
boot.mean[i]<-mean(sample(TL,replace=T))
}
#__________________________________________________________________________#
### PERCENTILE BOOTSTRAP CI
quantile(boot.mean,c(0.025,0.975))
#__________________________________________________________________________#
###Standard Boostrap CI
int.boot<-1.96*sd(boot.mean)
CIlow.boot<-mean.TL-int.boot
CIhi.boot<-mean.TL+int.boot
CIlow.boot
CIhi.boot
#__________________________________________________________________________#
###### ANOTHER approach with library 'boot' [From Crawley: The R Book]
#install.packages("boot")
library(boot)
mymean<-function(TL,i)mean(TL[i])
myboot<-boot(TL,mymean,R=1000)
myboot
# Percentile Bootstrap CI
quantile(myboot$t,c(0.025,0.975))
#Various Bootstrap CI
boot.ci(myboot)
#__________________________________________________________________________#
#Generating Random Numbers
#Of paramount importance when running Monte Carlo simulations
rm(list=ls())
#normal distribution
x <- rnorm(5000)
hist(x,20,freq=T)
plot(density(x))
x2<-runif(5000)
hist(x2,20,freq=T)
#normal distribution
x <- rnorm(5000)
hist(x,20,freq=T)
?rnorm
z1<-rnorm(500, mean = 1, sd = 0.3)
hist(z1,20,freq=T)
z2<-rnorm(500, mean = 3, sd = 0.3)
hist(z2)
plot(z1,z2)
z3<-runif(500, 0, 1)
z4<-runif(500, 0,1)
plot(z3,z4)
##Setting the 'seed' for random number generation
#IMPORTANT for checking simulations prior to full run
set.seed(2)  #sets the seed
rnorm(10)
set.seed(2)  #sets the seed
rnorm(10)
rnorm(10)		#note that the seed is not held indefinitely in memory)
set.seed(10)
rnorm(10)
rnorm(1)
set.seed(1)
rnorm(10)
set.seed(10)
rnorm(10)
## Simulate CORRELATED Data Using MVTNORM
##basic idea: simulate rnorm vectors, & multiply by decomposition of a covariance matrix
## covariance matrix specifies correlation structure
library(mvtnorm)
corr.val<-0.7
a <- rmvnorm(n=500,mean=c(0,0),sigma=matrix(c(1,corr.val,corr.val,1),2,2))
cor(a)
plot(a)
c(0,0)
matrix(c(1,corr.val,corr.val,1),2,2)
corr.val<-0.9
a <- rmvnorm(n=500,mean=c(0,0),sigma=matrix(c(1,corr.val,corr.val,1),2,2))
cor(a)
plot(a)
corr.val<- -0.9
a <- rmvnorm(n=500,mean=c(0,0),sigma=matrix(c(1,corr.val,corr.val,1),2,2))
cor(a)
plot(a)
#__________________________________________________________________________#
###Shuffle Data: i.e. resampling without replacement
rm(list=ls())
x <- 1:10
#dim(x)<-c(10,1) #force dimensions to make column vector
x
sample(x)	# Randomize the order of locations
sample(x)	# Randomize the order of locations
sample(x)	# Randomize the order of locations
sample(x)	# Randomize the order of locations
sample(x)	# Randomize the order of locations
class(x)
sample(x,replace=FALSE)	#more explicit
sample(x,replace=TRUE)	#more explicit
sample(x,(length(x)-2),replace=FALSE)	#sub-sample
#__________________________________________________________________________#
# WHEN SAMPLE CAN GET US IN TROUBLE!!!!!!
x <- 1:10
y<-cbind(x,x,x)
y
sample(y,replace=FALSE)    #We did not tell it to preserve rows!!
y
y[]
y[1,]
sample(nrow(y))
y[sample(nrow(y)),]   	   # ROWS Preserved (needed for resampling multivariate data)
y[sample(nrow(y)),]   	   # ROWS Preserved (needed for resampling multivariate data)
y[sample(nrow(y)),]   	   # ROWS Preserved (needed for resampling multivariate data)
y[sample(nrow(y)),]   	   # ROWS Preserved (needed for resampling multivariate data)
y[sample(nrow(y)),]   	   # ROWS Preserved (needed for resampling multivariate data)
#__________________________________________________________________________#
#Simple Randomization Test
rm(list=ls())
bumpus<-read.csv("Data/bumpus.csv",header=T)
View(bumpus)
class(bumpus)
bumpus$subject
bumpus$sex
bumpus.data<-log(bumpus[,(5:13)]) # set of log-linear measurements
sex<-as.factor(bumpus[,2])
TL<-bumpus.data$TL
#Observed data
t.test(formula=TL~sex)
plot(sex,bumpus.data$TL,ylab="Total Length")
plot(sex,TL,ylab="Total Length")
t.test(formula=bumpus.data$TL~sex)$statistic
t.obs<-t.test(formula=bumpus.data$TL~sex)$statistic[[1]]  #grab t-statistic from frame
t.obs
#Randomization Test
permute<-999
P.1tailed<-P.2tailed<-1
P.1tailed
t.rand.vec<-array(NA,(permute+1))
t.rand.vec
t.rand.vec[permute+1]<-t.obs
t.rand.vec
for(i in 1:permute){
###Shuffle Data
y.rand<-sample(bumpus.data$TL)  #NOTE: notation works ONLY for single variable
###Run analysis on random data
t.rand.vec[i]<-t.test(formula=y.rand~sex)$statistic[[1]]
}  #end permute
t.rand.vec
##Significance assessment
P.1tailed<-length(which(t.rand.vec<=t.rand.vec[permute+1])) / (permute+1)  #because observed is negative
P.2tailed<-length(which(abs(t.rand.vec)>=abs(t.rand.vec[permute+1]))) / (permute+1)
P.1tailed
P.2tailed
####Plot
hist(t.rand.vec,20,freq=T,col="gray")
segments(t.obs, 0, t.obs, 50)  ##Plot Observed value
system.time()
for(i in 1:permute){
###Shuffle Data
y.rand<-sample(bumpus.data$TL)  #NOTE: notation works ONLY for single variable
###Run analysis on random data
t.rand.vec[i]<-t.test(formula=y.rand~sex)$statistic[[1]]
}  #end permute
system.time
for(i in 1:permute){
###Shuffle Data
y.rand<-sample(bumpus.data$TL)  #NOTE: notation works ONLY for single variable
###Run analysis on random data
t.rand.vec[i]<-t.test(formula=y.rand~sex)$statistic[[1]]
}  #end permute
t.rand.vec <- t.obs
for(i in 1:permute){
###Shuffle Data
y.rand<-sample(bumpus.data$TL)  #NOTE: notation works ONLY for single variable
###Run analysis on random data
t.rand.vec<-rbind(t.rand.vec,t.test(formula=y.rand~sex)$statistic[[1]])
}  #end permute
tapply(TL,sex,mean)
diff(tapply(TL,sex,mean))
t.obs <- diff(tapply(TL,sex,mean))
t.rand.vec<-array(NA,(permute+1))
t.rand.vec[permute+1]<-t.obs
t.obs <- diff(tapply(TL,sex,mean))
t.rand.vec<-array(NA,(permute+1))
t.rand.vec[permute+1]<-t.obs
for(i in 1:permute){
###Shuffle Data
y.rand<-sample(bumpus.data$TL)  #NOTE: notation works ONLY for single variable
###Run analysis on random data
t.rand.vec[i]<-diff(tapply(y.rand,sex,mean))
}  #end permute
####Plot
hist(t.rand.vec,20,freq=T,col="gray")
segments(t.obs, 0, t.obs, 50)  ##Plot Observed value
sex
tapply(y.rand,sex,mean)
#__________________________________________________________________________#
# Bootstrapping Data
x <- 1:10
x
sample(x,replace=TRUE)
sample(x,replace=TRUE)
#Observed mean and CI
mean.TL<-mean(TL)
mean.TL
int<-1.96*sqrt(var(TL)/length(TL))
CIlow<-mean.TL-int
CIhi<-mean.TL+int
CIlow
CIhi
#Bootstrap data
boot.mean<-numeric(1000)
boot.mean
for (i in 1:1000){
boot.mean[i]<-mean(sample(TL,replace=T))
}
hist(boot.mean)
#__________________________________________________________________________#
### PERCENTILE BOOTSTRAP CI
quantile(boot.mean,c(0.025,0.975))
CIlow
CIhi
hist(TL)
#__________________________________________________________________________#
###Standard Boostrap CI
int.boot<-1.96*sd(boot.mean)
CIlow.boot<-mean.TL-int.boot
CIhi.boot<-mean.TL+int.boot
CIlow.boot
CIhi.boot
mean(boot.mean)
mean(TL)
#__________________________________________________________________________#
###### ANOTHER approach with library 'boot' [From Crawley: The R Book]
#install.packages("boot")
library(boot)
mymean<-function(TL,i)mean(TL[i])
myboot<-boot(TL,mymean,R=1000)
myboot
# Percentile Bootstrap CI
quantile(myboot$t,c(0.025,0.975))
#Various Bootstrap CI
boot.ci(myboot)
setwd("C:/DeanData/Teaching/EEOB590_AdvBiostat/BioStats/LabData")
bumpus<-read.csv("Data/bumpus.csv",header=T)

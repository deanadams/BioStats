library(geomorph)
?phylo.integration
data(plethspecies)
Y.gpa<-gpagen(plethspecies$land)    #GPA-alignment
land.gps<-c("A","A","A","A","A","B","B","B","B","B","B")
class(plethspecies$phy)
phylo.integration(A=Y.gpa$coords,A2=Y.gpa$Csize,
phy=plethspecies$phy,iter=999)
Y.gpa$coords
size <- Y.gpa$Csize
size
matrix(size)
phylo.integration(A=Y.gpa$coords,A2=size,
phy=plethspecies$phy,iter=999)
as.matrix(size)
phylo.integration(A=Y.gpa$coords,A2=as.matrix(size),
phy=plethspecies$phy,iter=999)
phylo.integration(A=as.matrix(size), A2=Y.gpa$coords
phy=plethspecies$phy,iter=999)
phylo.integration(A=as.matrix(size), A2=Y.gpa$coords,
phy=plethspecies$phy,iter=999)
names(Y.gpa$Csize)
rownames(size2) <- names(Y.gpa$Csize)
phylo.integration(A=Y.gpa$coords,A2=size2,
phy=plethspecies$phy,iter=999)
size2 <- as.matrix(Y.gpa$Csize)
rownames(size2) <- names(Y.gpa$Csize)
phylo.integration(A=Y.gpa$coords,A2=size2,
phy=plethspecies$phy,iter=999)
phylo.integration(A=size2, A2=Y.gpa$coords,
phy=plethspecies$phy,iter=999)
phylo.integration
devtools::install_github(geomorphR/geomorph, ref="Develop")
devtools::install_github("geomorphR/geomorph", ref="Develop")
devtools::install_github("geomorphR/geomorph", ref="Develop")
install.packages('parrdirs')
devtools::install_github("geomorphR/geomorph", ref="Develop")
devtools::install_github("geomorphR/geomorph", ref="Develop")
devtools::install_github("geomorphR/geomorph", ref="Develop")
devtools::install_github("geomorphR/geomorph", ref="Develop")
install.packages(c("bayesplot", "BH", "bipartite", "boot", "brio", "broom", "caTools", "class", "cli", "coin", "cpp11", "crayon", "crosstalk", "crul", "DBI", "dbplyr", "deldir", "DescTools", "distill", "dotCall64", "dplyr", "emmeans", "expm", "fansi", "fastmap", "forcats", "gert", "ggrepel", "ggthemes", "git2r", "glmnet", "hisse", "hms", "httpuv", "kableExtra", "knitcitations", "knitr", "koRpus", "ks", "libcoin", "lifecycle", "magick", "MASS", "mathjaxr", "matrixStats", "MCMCpack", "memoise", "mgcv", "mime", "multcomp", "nlme", "nnet", "OUwie", "pixmap", "plotrix", "pracma", "promises", "quantreg", "rcompanion", "RcppArmadillo", "reprex", "rgdal", "rgl", "ritis", "RSQLite", "rstatix", "Rvcg", "scholar", "segmented", "shiny", "shinythemes", "showtext", "sp", "spatial", "spatstat.data", "spatstat.utils", "sysfonts", "testthat", "tibble", "tinytex", "tkrplot", "tweedie", "usethis", "waldo", "withr", "xfun"))
devtools::install_giothub('geomorphR/geomorph', ref="Develop")
devtools::install_github('geomorphR/geomorph', ref="Develop")
devtools::install_github('geomorphR/geomorph', ref="Develop")
devtools::install_github('geomorphR/geomorph', ref="Develop")
devtools::install_github('geomorphR/geomorph', ref="Develop")
devtools::install_github('mlcollyer/RRPP')
devtools::install_github('geomorphR/geomorph', ref="Develop", force = TRUE)
install.packages(c("BH", "bipartite", "boot", "brio", "broom", "caTools", "class", "cli", "coin", "cpp11", "crayon", "crosstalk", "crul", "DBI", "dbplyr", "deldir", "DescTools", "distill", "dotCall64", "dplyr", "emmeans", "expm", "fansi", "fastmap", "forcats", "gert", "ggrepel", "ggthemes", "git2r", "glmnet", "hisse", "hms", "httpuv", "kableExtra", "knitcitations", "knitr", "koRpus", "ks", "libcoin", "magick", "MASS", "mathjaxr", "matrixStats", "MCMCpack", "memoise", "mgcv", "mime", "multcomp", "nlme", "nnet", "OUwie", "pixmap", "plotrix", "pracma", "promises", "quantreg", "rcompanion", "RcppArmadillo", "reprex", "rgdal", "rgl", "ritis", "RSQLite", "rstatix", "Rvcg", "scholar", "segmented", "shiny", "shinythemes", "showtext", "sp", "spatial", "spatstat.data", "spatstat.utils", "sysfonts", "testthat", "tibble", "tinytex", "tkrplot", "tweedie", "usethis", "waldo", "withr", "xfun"))
devtools::install_github('geomorphR/geomorph', ref="Develop")
library(geomorph)
?plotAllometry
# Simple allometry
data(plethodon)
Y.gpa <- gpagen(plethodon$land, print.progress = FALSE)    #GPA-alignment
gdf <- geomorph.data.frame(Y.gpa, site = plethodon$site,
species = plethodon$species)
fit <- procD.lm(coords ~ log(Csize), data=gdf, iter=0,
print.progress = FALSE)
# Predline
plotAllometry(fit, size = gdf$Csize, logsz = TRUE,
method = "PredLine", pch = 19)
# same as
logSize <- log(gdf$Csize)
plot(fit, type = "regression", reg.type = "PredLine",
predictor = logSize, pch = 19)
# RegScore
plotAllometry(fit, size = gdf$Csize, logsz = TRUE,
method = "RegScore", pch = 19)
# same as
plot(fit, type = "regression", reg.type = "RegScore",
predictor = logSize, pch = 19)
# CAC
plotAllometry(fit, size = gdf$Csize, logsz = TRUE,
method = "CAC", pch = 19)
# same (first plot) as
PLS <- two.b.pls(log(gdf$Csize), gdf$coords, print.progress = FALSE)
plot(PLS)
# Group Allometries
fit <- procD.lm(coords ~ Csize * species * site, data=gdf, iter=0,
print.progress = FALSE)
# CAC (should not change from last time; model change has no effect)
plotAllometry(fit, size = gdf$Csize, logsz = TRUE, method = "CAC",
pch = 19)
# Predline
plotAllometry(fit, size = gdf$Csize, logsz = TRUE, method = "PredLine",
pch = 19, col = as.numeric(interaction(gdf$species, gdf$site)))
# RegScore
plotAllometry(fit, size = gdf$Csize, logsz = TRUE, method = "RegScore",
pch = 19, col = as.numeric(interaction(gdf$species, gdf$site)))
pc.plot <- plotAllometry(fit, size = gdf$Csize, logsz = TRUE,
method = "size.shape",
pch = 19, col = as.numeric(interaction(gdf$species, gdf$site)))
summary(pc.plot$size.shape.PCA)
fit3 <- procD.lm(coords ~ species, data = gdf, iter = 0,
print.progress = FALSE)
plotAllometry(fit3, size = gdf$Csize, logsz = TRUE, method = "RegScore",
pch = 19, col = as.numeric(gdf$species))
# Group Allometries
fit <- procD.lm(coords ~ Csize + species * site, data=gdf, iter=0,
print.progress = FALSE)
# CAC (should not change from last time; model change has no effect)
plotAllometry(fit, size = gdf$Csize, logsz = TRUE, method = "CAC",
pch = 19)
# Predline
plotAllometry(fit, size = gdf$Csize, logsz = TRUE, method = "PredLine",
pch = 19, col = as.numeric(interaction(gdf$species, gdf$site)))
# Group Allometries
fit.c <- procD.lm(coords ~ Csize + species * site, data=gdf, iter=0,
print.progress = FALSE)
# Predline
plotAllometry(fit.c, size = gdf$Csize, logsz = TRUE, method = "PredLine",
pch = 19, col = as.numeric(interaction(gdf$species, gdf$site)))
# Group Allometries
fit <- procD.lm(coords ~ Csize * species * site, data=gdf, iter=0,
print.progress = FALSE)
# Predline
plotAllometry(fit, size = gdf$Csize, logsz = TRUE, method = "PredLine",
pch = 19, col = as.numeric(interaction(gdf$species, gdf$site)))
# Simple allometry
data(plethodon)
Y.gpa <- gpagen(plethodon$land, print.progress = FALSE)    #GPA-alignment
gdf <- geomorph.data.frame(Y.gpa, site = plethodon$site,
species = plethodon$species)
# Group Allometries
fit <- procD.lm(coords ~ Csize * species * site, data=gdf, iter=0,
print.progress = FALSE)
# Predline
plotAllometry(fit, size = gdf$Csize, logsz = TRUE, method = "PredLine",
pch = 19, col = as.numeric(interaction(gdf$species, gdf$site)))
# Group Allometries
fit.c <- procD.lm(coords ~ Csize + species * site, data=gdf, iter=0,
print.progress = FALSE)
# Predline
plotAllometry(fit.c, size = gdf$Csize, logsz = TRUE, method = "PredLine",
pch = 19, col = as.numeric(interaction(gdf$species, gdf$site)))
anova(fit)
# Group Allometries
fit <- procD.lm(coords ~ Csize * species * site, data=gdf, iter=999,
print.progress = FALSE)
anova(fit)
gps <- intersect(plethodon$site, plethodon$species)
gps
gps <- interaction(plethodon$site, plethodon$species)
gps
gdf <- geomorph.data.frame(Y.gpa, gps  = gps)
# Group Allometries
fit <- procD.lm(coords ~ Csize * gps, data=gdf, iter=999,
print.progress = FALSE)
anova(fit)
# Predline
plotAllometry(fit, size = gdf$Csize, logsz = TRUE, method = "PredLine",
pch = 19, col = as.numeric(interaction(gdf$species, gdf$site)))
# Predline
plotAllometry(fit, size = gdf$Csize, logsz = TRUE, method = "PredLine",
pch = 19, col = gps)
# Group Allometries
fit.c <- procD.lm(coords ~ Csize + gps, data=gdf, iter=999,
print.progress = FALSE)
anova(fit.c)
# Predline
plotAllometry(fit.c, size = gdf$Csize, logsz = TRUE, method = "PredLine",
pch = 19, col = gps)
devtools::install_github('geomorphR/geomorph', ref="Develop", build_vignettes = TRUE)
install.packages("rgl")
devtools::install_github('geomorphR/geomorph', ref="Develop", build_vignettes = TRUE)
setwd("C:/DeanData/Teaching/EEOB590_AdvBiostat/BioStats/LabData")
bumpus<-read.csv("Data/bumpus.csv",header=T)
bumpus.data<-log(as.matrix(bumpus[,(5:13)])) # matrix of log-linear measurements
sex<-as.factor(bumpus[,2])
surv<-as.factor(bumpus[,4])
SexBySurv<-as.factor(paste(sex,surv))
Y<-as.matrix(bumpus.data[,1])
X1<-bumpus.data[,2]
X2<-bumpus.data[,3]
library(RRPP)
mydat <- rrpp.data.frame(Y = Y, X1 = X1, X2 = X2, sex = sex, surv = surv, SexBySurv = SexBySurv)
#__________________________________________________________________________#
#simple linear regression  (Model I Regression)
lm(Y~X1)
#more information
model1<-lm(Y~X1)
summary(model1)	#provides regression coefficients
anova(model1)	#provides model term tests
plot(X1,Y,pch=21, bg="black", cex=2)
abline(model1,lwd=2,col="red")
#Lots of components in model, such as:
model1$fitted.values
model1$residuals
#Regression evaluated via residual randomization (RRPP)
model2 <- lm.rrpp(Y~X1, print.progress = FALSE, data = mydat)
anova(model2)
anova(model1)	#Identical to parametric results
coef(model2)
coef(model1)
#__________________________________________________________________________#
#### Model II Regression
library(lmodel2)
lmodel2(Y~X1,nperm=999)
RMA<-lmodel2(Y~X1)
plot(RMA, pch=21,cex=2, bg="black")
abline(model1,lwd=2,col="blue")
#__________________________________________________________________________#
#multiple regression
summary(lm(Y~X1+X2))
anova(lm(Y~X1+X2))
#via RRPP
anova(lm.rrpp(Y~X1+X2,print.progress = FALSE, data=mydat))
cor(X1,X2)  #hmm, there is multicollinearity in the X-variables. Perhaps use type II SS.
anova(lm.rrpp(Y~X1+X2,print.progress = FALSE, data=mydat,SS.type = "II"))
# Plot for multiple regression
#install.packages("scatterplot3d")
library(scatterplot3d)
plot<-scatterplot3d(X1,X2,Y)
plot$plane3d(lm(Y~X1+X2))
#__________________________________________________________________________#
#polynomial regression
fit  <- lm(Y~X1) #first degree
fit2 <- lm(Y~poly(X1,2,raw=TRUE))#second degree
fit3 <- lm(Y~poly(X1,3,raw=TRUE))#third degree
fit4 <- lm(Y~poly(X1,4,raw=TRUE))#fourth degree
#evaluate models
anova(fit)
anova(fit,fit2)  #In this case, adding polynomial terms NOT an improvement
anova(fit2,fit3)
anova(fit3,fit4)
plot(X1,Y)
abline(model1,col="red")
xx <-seq(min(X1),max(X1),length=100)
lines(xx, predict(fit2, data.frame(X1=xx)), col="blue")
lines(xx, predict(fit3, data.frame(X1=xx)), col="green")
lines(xx, predict(fit4, data.frame(X1=xx)), col="purple")
#__________________________________________________________________________#
###ANCOVA
anova(lm(Y~X2*SexBySurv))
#Implies slopes for M and F statistically equivalent, so drop and re-run
anova(lm(Y~X2+SexBySurv))
model.ancova<-lm(Y~X2+SexBySurv)
56/2000
############ let us begin with a comparison of implementations
mymean<-function(x){
n<-length(x)
tmp<-0
for (i in 1:n){
tmp<-tmp+x[i]
}
mn<-tmp/n
return(mn)
}
x<-matrix(rnorm(1000))
n<-length(x)
library(microbenchmark)
library(ggplot2)
microbenchmark(mean(x),apply(x,2,mean), sum(x)/length(x),mymean(x),colSums(x)/length(x))
############ Evaluating choke-points in code
#Example
library(aprof)
source("07-pls.slow.r")
tmp<-tempfile() #create tmp file for saving profiler output
Rprof(tmp,line.profiling=TRUE)  #profile the function
x<-matrix(rnorm(1000),ncol=10)
y<-matrix(rnorm(1000),ncol=10)
pls.slow(x,y)
Rprof(append=FALSE)
fooaprof<-aprof("07-pls.slow.r",tmp) #Create aprof object
plot(fooaprof)
iter<-99
SS<-array(NA,iter) #pre-allocate
newSS<-function(iter){ #'on the fly'
SS<-NULL
for (i in 1:iter){SS<-rbind(SS,NA)}
return(SS)
}
microbenchmark(SS<-array(NA,99), x<-newSS(99))
microbenchmark(SS<-array(NA,9999), x<-newSS(9999),times=10)
x<-cbind(1,matrix(rnorm(1000),ncol=10))
y<-matrix(rnorm(100))
all.calc<-function(x,y){
coef.r<-array(NA,dim=c(999,ncol(x)))
for (i in 1:999){
y.r<-y[sample(nrow(y)),]
coef.r[i,]<-solve(t(x)%*%x)%*%t(x)%*%y.r
}
}
hat.calc<-function(x,y){
hat<-solve(t(x)%*%x)%*%t(x)
coef.r<-array(NA,dim=c(999,ncol(x)))
for (i in 1:999){
y.r<-y[sample(nrow(y)),]
coef.r[i,]<-hat%*%y.r
}
}
microbenchmark(all.calc(x,y),hat.calc(x,y),times=10)
#3:  Use lower-level functions
x<-matrix(rnorm(10000),ncol=2)
xf<-cbind(1,x)
y<-matrix(rnorm(nrow(x)))
lm(y~x)  #Common method
solve(t(xf)%*%xf)%*%t(xf)%*%y
crossprod(solve(crossprod(xf)),crossprod(xf,y))
lm.fit(xf,y)$coefficients
.lm.fit(xf,y)$coefficients  ### NOTE: a very low-level function (cannot use in packages submitted to CRAN)
qr.coef(qr(xf),y)
microbenchmark(
lm(y~x),
solve(t(xf)%*%xf)%*%t(xf)%*%y,
crossprod(solve(crossprod(xf)),crossprod(xf,y)),
lm.fit(xf,y),.lm.fit(xf,y),
qr.coef(qr(xf),y)
)
###NOTE that the best implementation can change with the size of the data matrix
#Large X univ. Y
x<-matrix(rnorm(10000),ncol=50)
xf<-cbind(1,x)
y<-matrix(rnorm(nrow(x)))
microbenchmark(
lm(y~x),
solve(t(xf)%*%xf)%*%t(xf)%*%y,
crossprod(solve(crossprod(xf)),crossprod(xf,y)),
lm.fit(xf,y),.lm.fit(xf,y),
qr.coef(qr(xf),y)
)
x<-matrix(rnorm(nrow(y)))
xf<-cbind(1,x)
##Large Y univ. X
y<-matrix(rnorm(10000),ncol=100)
microbenchmark(
lm(y~x),
solve(t(xf)%*%xf)%*%t(xf)%*%y,
crossprod(solve(crossprod(xf)),crossprod(xf,y)),
lm.fit(xf,y),.lm.fit(xf,y),
qr.coef(qr(xf),y)
)
#large Y and X
y<-matrix(rnorm(20000),ncol=100)
x<-matrix(rnorm(10000),ncol=50)
xf<-cbind(1,x)
microbenchmark(
lm(y~x),
solve(t(xf)%*%xf)%*%t(xf)%*%y,
crossprod(solve(crossprod(xf)),crossprod(xf,y)),
lm.fit(xf,y),.lm.fit(xf,y),
qr.coef(qr(xf),y)
)
##Large Y univ. X
y<-matrix(rnorm(10000),ncol=100)
x<-matrix(rnorm(nrow(y)))
xf<-cbind(1,x)
microbenchmark(
lm(y~x),
solve(t(xf)%*%xf)%*%t(xf)%*%y,
crossprod(solve(crossprod(xf)),crossprod(xf,y)),
lm.fit(xf,y),.lm.fit(xf,y),
qr.coef(qr(xf),y)
)
#large Y and X
y<-matrix(rnorm(20000),ncol=100)
x<-matrix(rnorm(10000),ncol=50)
xf<-cbind(1,x)
microbenchmark(
lm(y~x),
solve(t(xf)%*%xf)%*%t(xf)%*%y,
crossprod(solve(crossprod(xf)),crossprod(xf,y)),
lm.fit(xf,y),.lm.fit(xf,y),
qr.coef(qr(xf),y)
)
#4: Vectorize when possible. Don't speak R with a 'C accent'
fn1<-function(x){
means<-array(0,ncol(x))
for(i in 1:ncol(x)){
for(j in 1:nrow(x)){
means[i]<-means[i]+x[j,i]
}
}
means<-means/nrow(x)
return(means)
}
x<-matrix(rnorm(1000*1000),ncol=1000)
microbenchmark(fn1(x),colMeans(x),apply(x,2,mean),times=10)
###
x <- matrix(rnorm(1000*10000), ncol=1000)
fn1<-function(x){
mx <- rep(NA, nrow(x))
for(i in 1:nrow(x)){ mx[i] <- max(x[i,])  }
return(mx)
}
microbenchmark(fn1(x),apply(x,1,max),times=10)  #loop is faster here
source('07-pls.slow.r')
x<-matrix(rnorm(10000),ncol=10)
y<-matrix(rnorm(20000),ncol=20)
microbenchmark(pls.slow(x,y),pls.fast(x,y),times=5)
#####PLS: compare new and old versions
source('07-pls.fast.r')
setwd("C:/DeanData/Teaching/EEOB590_AdvBiostat/BioStats/LabData")
#####PLS: compare new and old versions
source('07-pls.fast.r')
source('07-pls.slow.r')
x<-matrix(rnorm(10000),ncol=10)
y<-matrix(rnorm(20000),ncol=20)
microbenchmark(pls.slow(x,y),pls.fast(x,y),times=5)
View(pls.fast)
View(pls.slow)
########################
#	PCA: Principal Components Analysis
library(RRPP)
library(vegan)
bumpus<-read.csv("data/bumpus.csv",header=T)
Y<-bumpus[,5:12]
Y <- scale(Y, scale = FALSE) #center data
gp.bumpus <- bumpus$sex
pca.bumpus<-prcomp(Y)
summary(pca.bumpus)
PC.scores<-pca.bumpus$x
pca.bumpus$rotation[,1]  #1st PC axis only
plot(PC.scores,xlab="PC I", ylab="PC II",asp=1,pch=21,bg=gp.bumpus,cex = 1.5)
plot(PC.scores,xlab="PC I", ylab="PC II",asp=1,pch=21,bg=as.factor(gp.bumpus),cex = 1.5)
legend("topright", levels(gp.bumpus), pch = 21)
Y <- scale(Y, scale = FALSE) #center data
gp.bumpus <- as.factor(bumpus$sex)
pca.bumpus<-prcomp(Y)
summary(pca.bumpus)
PC.scores<-pca.bumpus$x
pca.bumpus$rotation[,1]  #1st PC axis only
plot(PC.scores,xlab="PC I", ylab="PC II",asp=1,pch=21,bg=gp.bumpus,cex = 1.5)
legend("topright", levels(gp.bumpus), pch = 21)
legend("topright", levels(gp.bumpus), pch = 21, col=levels(gp.bumpus))
legend("topright", levels(gp.bumpus), pch = 21,bg=gp.bumpus)
legend("topright", levels(gp.bumpus), pch = 21,col=gp.bumpus)
legend("topright", levels(gp.bumpus), pch = 21,col=levels(gp.bumpus))
gp.bumpus
legend("topright", levels(gp.bumpus), pch = 21,pt.bg=levels(gp.bumpus))
?legend
legend("topright", levels(gp.bumpus), pch = 21,pt.bg=1:2)
########################
#	PCA: Principal Components Analysis
library(RRPP)
library(vegan)
bumpus<-read.csv("data/bumpus.csv",header=T)
Y<-bumpus[,5:12]
Y <- scale(Y, scale = FALSE) #center data
gp.bumpus <- as.factor(bumpus$sex)
pca.bumpus<-prcomp(Y)
summary(pca.bumpus)
PC.scores<-pca.bumpus$x
pca.bumpus$rotation[,1]  #1st PC axis only
plot(PC.scores,xlab="PC I", ylab="PC II",asp=1,pch=21,bg=gp.bumpus,cex = 1.5)
legend("topright", levels(gp.bumpus), pch = 21,pt.bg=1:2)
#Eigenvalue analysis via broken stick model
screeplot(pca.bumpus,bstick = TRUE)  #implies 2 PCAs sufficient graphical representation
##Plot of actual vs. PC1-2 distances
plot(dist(Y),dist(PC.scores[,1:2]))
cor(dist(Y),dist(PC.scores[,1:2]))
### PCA via svd
svd.res<-svd(Y)
svd.res$d^2/sum(svd.res$d^2)   #same % variation per PC axis
pc.scores.svd<-svd.res$u%*%diag(svd.res$d)  #PCA scores
plot(pc.scores.svd,asp=1)
plot(pc.scores.svd,asp=1, pch=21,bg=gp.bumpus,cex = 1.5)
legend("topright", levels(gp.bumpus), pch = 21,pt.bg=1:2)
#### PCA "by hand" via eigen-analysis
vcv.bumpus<-var(Y)	#Calculate PC axes
pc.bumpus<-eigen(vcv.bumpus)
pc.bumpus$values/sum(pc.bumpus$values)   #same % variation per PC axis
pc.scores<-Y%*%pc.bumpus$vectors	#Projection
plot(pc.scores,xlab="PC I", ylab="PC II",asp=1,pch=21,bg=gp.bumpus,cex = 1.5)
legend("topright", levels(gp.bumpus), pch = 21,pt.bg=1:2)
#############Biplot with PCA
biplot(pca.bumpus)
###########################
# 	PCoA
bumpus.dist<-dist(Y)
PCoA<-cmdscale(bumpus.dist)   #from vegan
plot(PCoA,pch=21,bg=gp.bumpus,cex=1.5,asp=1)
legend("topright", levels(gp.bumpus), pch = 21,pt.bg=1:2)
#############################
#	NMDS
bumpus.nmds <- metaMDS(bumpus.dist, autotransform=FALSE, k=2)
#A nice function. Runs 20 times with different starting points; tries to avoid local optima
plot(bumpus.nmds$points, asp=1,pch=21, bg=gp.bumpus, cex=1.5,xlab="NMDS1", ylab="NMDS2")
legend("topright", levels(gp.bumpus), pch = 21,pt.bg=1:2)
#Plot of actual to plot distances (often curved)
plot(bumpus.dist, dist(scores(bumpus.nmds, display='sites'), method='eucl'), xlab='D.obs', ylab='D.plot')
data(dune)  #from vegan
dune
dune.dist<-vegdist(dune)  #default = Bray-Curtis distance
dune.nmds <- metaMDS(dune.dist, autotransform=FALSE, k=2)
#A nice function. Runs 20 times with different starting points; tries to avoid local optima
plot(dune.nmds)
plot(dune.nmds,type='t')
#Plot of actual to plot distances (often curved)
plot(dune.dist, dist(scores(dune.nmds, display='sites'), method='eucl'), xlab='D.obs', ylab='D.plot')
#################
#Correspondence Analysis
dune.cca<-cca(dune)  #from vegan
plot(dune.cca)
#Detrended Correspondence Analysis
dune.dca<-decorana(dune)
plot(dune.dca)
pca.bumpus<-prcomp(Y)
PC.scores<-pca.bumpus$x
plot(PC.scores,xlab="PC I", ylab="PC II",asp=1,pch=21,bg=gp.bumpus,cex = 1.5)
legend("topright", levels(gp.bumpus), pch = 21,pt.bg=1:2)
pc.bird<-prcomp(Y)
p.var<-pc.bird$sdev^2/sum(pc.bird$sdev^2)
p.var
pc.bird$rotation[,1]
pca.bumpus$sdev^2 / sum(pca.bumpus$sdev^2)
pca.bumpus$rotation[,1]
PCoA<-cmdscale(dist(Y))
plot(-1*PCoA[,1],PCoA[,2],pch=21,bg=gp.bumpus,cex=1.5,asp=1)
legend("topright", levels(gp.bumpus), pch = 21,pt.bg=1:2)
setwd("C:/DeanData/Teaching/EEOB590_AdvBiostat/BioStats/LabData")
